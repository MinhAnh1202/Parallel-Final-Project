{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeblyKIuybIm"
   },
   "source": [
    "# Báo cáo Đồ án Cuối kì - Lập trình Song song\n",
    "##### Nhóm 9:\n",
    "##### Đoàn Thị Minh Anh - 22120213\n",
    "##### Trần Hoàng Kim Ngân - 22120224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwJ5HgSPzBZU"
   },
   "source": [
    "## 1. Mô tả bài toán:\n",
    "### 1.1. Phát biểu bài toán:\n",
    "- Xác định bài toán phân loại ảnh:  \n",
    "  - Bài toán: Học đặc trưng không giám sát từ bộ dữ liệu ảnh CIFAR-10 bằng Autoencoder rồi dùng ác đặc trưng đã học để huấn luyện một bộ phân loại SVM cho nhiệm vụ phân loại 10 lớp.\n",
    "  - Quy trình:\n",
    "    - Huấn luyện Autoencoder trên toàn bộ ảnh huấn luyện không dùng nhãn để tối thiểu hóa loss MSE. Encoder xuất ra vector đặc trưng có kích thước 8192 cho mỗi ảnh.\n",
    "    - Dùng encoder đã huấn luyện để trích xuất đặc trưng cho tập huấn luyện và tập kiểm tra, rồi huấn luyện SVM sử dụng các nhãn lớp.\n",
    "    - Đánh giá hiệu năng SVM.  \n",
    "  - Mục tiêu: Chứng minh rằng đặc trưng học được từ Autoencoder giúp phân loại hiệu quả và triển khai CUDA để chạy autoencoder trên GPU hỗ trợ tăng tốc đáng kể so với chạy bằng CPU.\n",
    "- Mô tả động lực tăng tốc GPU:\n",
    "  - Bài toán đòi hỏi xử lý một lượng lớn phép tính số học, đặc biệt trong các tầng tích chập (Convolution), phép nhân ma trận và lan truyền ngược. Việc triển khai các phép tính này trên CPU theo tuần tự thường rất mất thời gian và kém hiệu quả. Trong khi đó, các phép tính này đều có khả năng song song hóa cao, hoàn toàn có thể triển khai một cách hợp lý để ứng dụng GPU.\n",
    "  - Bộ dữ liệu CIFAR-10 với 50,000 ảnh train và 10,000 ảnh test đòi hỏi khả năng truy xuất bộ nhớ mạnh mẽ. Tận dụng GPU tốt sẽ giúp hệ thống xử lý dữ liệu hiệu quả hơn, đạt tốc độ huấn luyện nhanh hơn và cải thiện chất lượng đặc trưng thu được cho nhiệm vụ phân loại hình ảnh.\n",
    "### 1.2. Tổng quan về bộ dữ liệu CIFAR-10:\n",
    "- Đặc tả tập dữ liệu (kích thước, lớp, phân chia):\n",
    "  - Kích thước ảnh: 32x32 pixels (RGB).\n",
    "  - 10 lớp gồm: airplane,automobile, bird, cat, deer, dog, frog, horse, ship, truck.\n",
    "  - Training set: 50,000 ảnh (5,000 ảnh/lớp).\n",
    "  - Test set: 10,000 ảnh (1,000 ảnh/lớp).\n",
    "  - Tổng số ảnh: 60,000 ảnh\n",
    "  - Format: File nhị phân với giá trị pixel uint8.\n",
    "- Hiển thị hình ảnh mẫu từ mỗi lớp (visualization):\n",
    "![Hình minh họa CIFAR-10](https://drive.google.com/uc?export=view&id=1Gy6BtsEWLgvlRHhyh5M7H5PCLy76H9Ss)\n",
    "\n",
    "- Giải thích các bước tiền xử lý dữ liệu (normalization, format):\n",
    "  - Chuyển đổi kiểu dữ liệu: Dữ liệu pixel gốc trong file ảnh là uint8, là số nguyên 8-bit không dấu nằm trong khoảng [0,255]. Để tiện cho việc chuẩn hoá các giá trị về khoảng [0,1], ở đây chúng em sẽ chuyển chúng về kiểu float.\n",
    "  - Chuyển về [0,1]: Sau khi chuyển sang kiểu số thực, các giá trị pixel sẽ được chuẩn hoá về khoảng [0,1]. Việc này giúp mạng nơ-ron hội tụ nhanh hơn và hoạt động ổn định hơn.\n",
    "### 1.3. Kiến trúc Autoencoder:\n",
    "- Mô tả kiến ​​trúc mạng bằng sơ đồ\n",
    "\n",
    "![Hình sơ đồ kiến trúc mạng](https://drive.google.com/uc?export=view&id=1TZZe0q-VkPQI0rTmbzO1prhDyyeocfeE)\n",
    "- Xác định kích thước và phép biến đổi lớp\n",
    "| Khối | Lớp | Tham số chính | Input shape | Output shape |\n",
    "|---|---|---|---|---|\n",
    "| Input | - | - | (32, 32, 3) | (32, 32, 3) |\n",
    "| Encoder | Conv2D + ReLU | 256 filters, K=3, pad=1, stride=1 | (32, 32, 3) | (32, 32, 256) |\n",
    "| Encoder | MaxPool2D | 2×2, stride=2 | (32, 32, 256) | (16, 16, 256) |\n",
    "| Encoder | Conv2D + ReLU | 128 filters, K=3, pad=1, stride=1 | (16, 16, 256) | (16, 16, 128) |\n",
    "| Encoder | MaxPool2D | 2×2, stride=2 | (16, 16, 128) | **(8, 8, 128)** |\n",
    "| Latent | Flatten (khi trích đặc trưng) | 8×8×128 = 8192 | (8, 8, 128) | **(8192, )** |\n",
    "| Decoder | Conv2D + ReLU | 128 filters, K=3, pad=1, stride=1 | (8, 8, 128) | (8, 8, 128) |\n",
    "| Decoder | UpSample2D | scale=2 | (8, 8, 128) | (16, 16, 128) |\n",
    "| Decoder | Conv2D + ReLU | 256 filters, K=3, pad=1, stride=1 | (16, 16, 128) | (16, 16, 256) |\n",
    "| Decoder | UpSample2D | scale=2 | (16, 16, 256) | (32, 32, 256) |\n",
    "| Output | Conv2D | 3 filters, K=3, pad=1, stride=1 | (32, 32, 256) | (32, 32, 3) |\n",
    "\n",
    "- Giải thích cấu trúc bộ mã hóa-giải mã và biểu diễn latent\n",
    "  - Encoder (downsampling path): Hai lớp Conv+ReLU giúp học đặc trưng cục bộ (biên, texture) còn MaxPool giúp nèn thông tin và tăng tính bất biến theo dịch chuyển. Kết quả cuối encoder là tensor (8, 8, 128). Khi trích đặc trưng để phân loại, tensor này được flatten thành vector 8192 chiều.\n",
    "  - Latent space: là nút thắt cổ chai chưa thông tin quan trọng nhất để tái tạo ảnh. Latent càng tốt thì ảnh reconstruct càng gần ảnh gốc.\n",
    "  - Decoder (upsampling path): đối xứng với encoder, dùng UpSample để đảo quá trình downsample và Conv nhằm tái tạo ảnh về (32, 32, 3). Lớp cuối không dùng activation, thườngđể mô hình tự học giá trị tái tạo.\n",
    "### 1.4. Mục tiêu đồ án:\n",
    "- Mục tiêu hiệu suất (thời gian luyện tập, mục tiêu\n",
    "tăng tốc, độ chính xác): Đồ án hướng đến xây dựng một hệ thống trích chọn đặc trưng và phân loại ảnh hiệu quả trên tập dữ liệu CIFAR-10. Các mục tiêu hiệu suất chính gồm:\n",
    "  - Giảm thời gian huấn luyện bằng cách tận dụng GPU và tối ưu các bước tính toán quan trọng trong Autoencoder.\n",
    "  - Đạt được tốc độ tăng tốc (speedup) đáng kể so với phiên bản chạy trên CPU.\n",
    "  - Đạt độ chính xác phân loại thỏa yêu cầu tối hiểu (khoảng 55-65%).\n",
    "- Mục tiêu học tập kỹ thuật: Đồ án giúp nhóm phát triển kiến thức, kỹ năng liên quan đến học máy và kỹ năng lập trình song song trên GPU, cụ thể:\n",
    "  - Hiểu và triển khai được kiến trúc Autoencoder cho bài toán học đặc trưng không giám sát.\n",
    "  - Nắm vững quy trình huấn luyện mô hình học sâu (forward, backward, tối ưu, đánh giá).\n",
    "  - Thực hành lập trình song song trên GPU bằng CUDA.\n",
    "  - Tối ưu hóa các tác vụ tính toán như biến đổi tensor, tích chập, nhân ma trận nhằm khai thác tối đa khả năng song song của GPU.\n",
    "- Tiêu chí thành công\n",
    "  - Chức năng đúng: Autoencoder huấn luyện thành công, tái tạo ảnh hợp lý và bộ phân loại hoạt động chính xác.\n",
    "  - Trích chọn đặc trưng hiệu quả: đặc trưng nén từ Autoencoder giúp cải thiện độ chính xác phân loại so với baseline.\n",
    "  - Tăng tốc rõ rệt khi chuyển từ CPU sang GPU, với báo cáo định lượng (speedup, thời gian huấn luyện).\n",
    "  - Kết quả thực nghiệm đầy đủ bao gồm biểu đồ loss, accuracy, tốc độ huấn luyện, hình ảnh tái tạo, confusion matrix.\n",
    "  - Báo cáo hoàn chỉnh, phân tích hợp lý và giải thích được tác động của GPU trong toàn hệ thống."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FIBQ2thzfXk"
   },
   "source": [
    "## 2. Các giai đoạn triển khai:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vj9C96f-zsMQ"
   },
   "source": [
    "### 2.1. CPU cơ bản\n",
    "#### Mục tiêu:\n",
    "- Mục tiêu nhóm muốn đạt được trong giai đoạn này:\n",
    "  - Xây dựng một phiên bản hoàn chỉnh của autoencoder trên CPU để làm baseline tham chiếu cho các phiên bản GPU sau này.\n",
    "  - Triển khai đầy đủ các layer cần thiết (Convolution, ReLU, MaxPooling, Upsampling, MSE Loss) cùng forward và backward pass trên CPU để đảm bảo mô hình có thể train được và đạt được reconstruction loss hợp lý.\n",
    "  - Đo lường thời gian huấn luyện và hiệu suất ban đầu trên CPU, từ đó xác định rõ các điểm nghẽn hiệu năng (bottleneck) để làm cơ sở cho việc tối ưu hóa trên GPU ở các phase tiếp theo.\n",
    "  - Có thể tạo ra một phiên bản đúng và có thể chạy được để dễ dàng so sánh kết quả với các phiên bản GPU khác và làm nền tảng cho việc chuyển đổi sang code CUDA.\n",
    "- Tại sao giai đoạn này là cần thiết:\n",
    "  - Kiểm chứng độ chính xác: Lập trình song song trên GPU vốn phức tạp với các vấn đề về đồng bộ luồng và quản lý bộ nhớ. Khi kết quả đầu ra bị sai lệch, rất khó để phân định nguyên nhân đến từ lỗi logic thuật toán hay lỗi kỹ thuật song song. Phiên bản CPU hoạt động như một chân lý (Ground Truth) tin cậy. Trong các giai đoạn sau, kết quả từ GPU sẽ được so sánh trực tiếp với CPU để đảm bảo tính đúng đắn trước khi tính đến hiệu năng.\n",
    "  - Nhận diện điểm nghẽn: Việc chạy trên CPU giúp xác định lớp nào (Convolution, Pooling hay Upsampling) chiếm nhiều thời gian xử lý nhất. Đây là chỉ dẫn quan trọng để biết nên dồn lực tối ưu vào lớp nào khi chuyển sang GPU.\n",
    "  - Thấu hiểu sâu sắc kiến trúc giải thuật: Việc chuyển đổi trực tiếp một công thức toán học sang CUDA kernel là rất rủi ro nếu chưa hiểu rõ luồng dữ liệu. Việc tự tay cài đặt các lớp phức tạp như Convolution hay MaxPooling bằng các vòng lặp tường minh giúp lập trình viên nắm bắt tường tận cơ chế truy cập bộ nhớ, cách xử lý biên và sải bước (stride).\n",
    "#### Chi tiết triển khai:\n",
    "- Cách tải và tiền xử lý dữ liệu CIFAR-10:\n",
    "\n",
    "  Chúng em tải bộ dữ liệu CIFAR-10 dạng binary nguyên bản từ trang web chính thức của tác giả.\n",
    "\n",
    "  Bộ dữ liệu gồm 5 file training batch (`data_batch_1.bin` đến `data_batch_5.bin`) và 1 file test batch (`test_batch.bin`).\n",
    "\n",
    "  Mỗi bản ghi trong các file có đúng *3073* bytes, được sắp xếp như sau:  \n",
    "  - Byte 0: nhãn lớp (1 byte, giá trị 0-9).\n",
    "  - Byte 1-1024: toàn bộ kênh màu đỏ (1024 pixel).\n",
    "  - Byte 1025-2048: toàn bộ kênh màu xanh lá (1024 pixel).\n",
    "  - Byte 2049-3072: toàn bộ kênh màu xanh lam (1024 pixel).\n",
    "\n",
    "  Quy trình đọc và tiền xử lý dữ liệu được thực hiện như sau:\n",
    "\n",
    "  - Mở và đọc lần lượt từng file binary theo đúng thứ tự.\n",
    "  - Với mỗi bản ghi 3073 bytes, tách riêng 1 byte nhãn và 3072 byte pixel.\n",
    "  - Chuyển ngay 3072 byte pixel từ kiểu `uint8` sang `float` trong quá trình đọc, đồng thời giữ nguyên thứ tự kênh R, G và B như file gốc.\n",
    "  - Lưu toàn bộ dữ liệu ảnh train (50.000 ảnh) và test (10.000 ảnh) vào các mảng float liên tục trong bộ nhớ host với kích thước là *N * 3072*.\n",
    "  - Sau khi tải xong, thực hiện chuẩn hóa một lần duy nhất bằng cách chia toàn bộ giá trị pixel cho 255.0 để đưa về khoảng [0.0, 1.0].\n",
    "  - Để hỗ trợ mini-batch training, chúng em duy trì một mảng chỉ số `train_indices[50000]`. Ở đầu mỗi epoch, hàm `shuffle_cifar10()` sử dụng thuật toán Fisher-Yates shuffle để xáo trộn ngẫu nhiên thứ tự ảnh.\n",
    "  - Hàm `get_next_batch()` sao chép nhanh dữ liệu batch từ `train_images` vào bộ nhớ đích bằng `memcpy`, đảm bảo hiệu suất cao và dễ dàng chuyển đổi sang GPU ở các phase sau.\n",
    "- Mô tả cách triển khai các lớp (Convolution, ReLU, MaxPool, UpSample):\n",
    "  1) Convolution:\n",
    "  - Forward: Hàm `Conv2D_Forward` thực hiện phép tích chập chuẩn với padding = 1, stride = 1, kernel 3x3. Duyệt theo thứ tự NCHW, hỗ trợ nhiều input và output channels. Bias được cộng trực tiếp sau tích chập.\n",
    "  - Backward: Tương tự với phiên bản forward, backward cũng thực hiện duyệt mảng theo thứ tự NCHW.\n",
    "    - Input: Hàm `Conv2D_Backward_Input` thực hiện full convolution giữa gradient từ lớp sau (d_output) với kernel đã được xoay 180°. Kết quả được cộng dồn vào đúng vị trí tương ứng trên input gradient.\n",
    "    - Weight: Hàm `Conv2D_Backward_Kernel` thực hiện tích chập giữa input của lớp hiện tại và gradient từ lớp sau (d_output), sau đó cộng dồn vào ma trận gradient trọng số.\n",
    "    - Bias: Hàm `Conv2D_Backward_Biases` thực hiện với mỗi filter, gradient của bias bằng tổng tất cả các giá trị gradient tương ứng trên toàn bộ feature map đầu ra (d_output).\n",
    "  2) ReLU:\n",
    "  - Forward: Với từng phần tử, thực hiện so sánh giá trị input[i], với i là index hiện tại trong mảng đầu vào, với 0.0f nhằm đảm bảo đầu ra luôn dương.\n",
    "  - Backward: Hàm `Relu_Backward` nhân gradient từ lớp sau với 1 nếu input > 0, ngược lại bằng 0, đảm bảo gradient chỉ lan truyền qua các neuron dương.\n",
    "  3) MaxPool:\n",
    "  - Forward: Hàm `MaxPool2D_Forward` thực hiện pooling 2x2, stride = 2, giảm kích thước không gian xuống một nửa. Với mỗi vị trí output, tìm giá trị lớn nhất trong vùng 2x2 của từng kênh.\n",
    "  - Backward: Hàm `MaxPool2D_Backward` chỉ truyền gradient về đúng vị trí có giá trị max trong forward pass và các vị trí còn lại nhận giá trị 0.\n",
    "  4) UpSample:\n",
    "  - Forward: Hàm `UpSample2D_Forward` thực hiện nearest-neighbor upsampling với scale_factor = 2. Mỗi pixel đầu vào được sao chép vào khối 2x2 tương ứng trên output.\n",
    "  - Backward: Hàm `UpSample2D_Backward` cộng dồn gradient từ toàn bộ khối 2x2 của output về đúng pixel gốc trên input.\n",
    "- Vòng lặp huấn luyện được cấu trúc như sau:\n",
    "  1) Lặp qua các epoch: Chúng em huấn luyện trong 20 epoch.\n",
    "  2) Xáo trộn dữ liệu: Ở đầu mỗi epoch, hàm `shuffle_cifar10(&data)` được gọi để áp dụng thuật toán Fisher-Yates shuffle trên mảng `train_indices`, đảm bảo thứ tự các ảnh được thay đổi ngẫu nhiên, giúp mô hình học tốt hơn và tránh bias theo thứ tự file.\n",
    "  3) Xử lý từng mini-batch:\n",
    "  - Số batch mỗi epoch được tính tự động bằng công thức: `num_batches = train_subset_size / batch_size`, ở đây do có những giới hạn về bộ nhớ, nên chúng em chỉ gán `train_subset_size = 1000` (chỉ train với 1000 ảnh). Ngoài ra, nhóm áp dụng `batch_size = 32`.\n",
    "  - Với mỗi batch_id, hàm `get_next_batch()` sao chép nhanh dữ liệu từ `train_images` (theo thứ tự đã shuffle) vào bộ nhớ tạm `batch_images` bằng `memcpy`.\n",
    "  - Dữ liệu batch được copy vào batch_input của struct autoencoder (buffer đã được cấp sẵn trong struct CPUAutoEncoder) để các hàm forward/backward có thể truy cập trực tiếp.\n",
    "  4) Quy trình huấn luyện một batch:\n",
    "  - Forward pass: Gọi hàm dành cho forward để tính lần lượt output của tất cả các layer từ input đến reconstructed output.\n",
    "  - Tính loss: Sử dụng hàm để tính Mean Squared Error giữa ảnh gốc (batch_input) và ảnh tái tạo (final_output). Loss của batch hiện tại được hiển thị trên terminal.\n",
    "  - Backward pass: Gọi hàm dành cho backward để tính gradient cho tất cả các layer theo thứ tự ngược lại.\n",
    "  - Cập nhật tham số: Gọi hàm cập nhật để áp dụng Gradient Descent với `learning rate = 0.001`, cập nhật trọng số và bias của tất cả các lớp Convolution.\n",
    "- Một vài đoạn mã chính:\n",
    "  1) Cấu trúc hàm Conv2D():\n",
    "  ```c\n",
    "  void Conv2D_Forward(float* input, int input_width, int input_height, int input_channels,\n",
    "    float* kernel, int kernel_width, int kernel_height,\n",
    "    float* biases, int padding, int stride, int filter_count,\n",
    "    float* output, int output_height, int output_width) \n",
    "  {\n",
    "      // Lặp qua kênh đầu ra (filter)\n",
    "      for (int c_out = 0; c_out < filter_count; c_out++) {  \n",
    "          // Lặp qua chiều cao output\n",
    "          for (int h_out = 0; h_out < output_height; h_out++) {\n",
    "              // Lặp qua chiều rộng output\n",
    "              for (int w_out = 0; w_out < output_width; w_out++) {\n",
    "                  // Lặp qua kênh đầu vào (c_in)\n",
    "                  for (int c_in = 0; c_in < input_channels; c_in++) {\n",
    "                      // Lặp qua kernel height\n",
    "                      for (int k_h = 0; k_h < kernel_height; k_h++) {\n",
    "                          // Lặp qua kernel width\n",
    "                          for (int k_w = 0; k_w < kernel_width; k_w++) {\n",
    "                              // Tính toán vị trí input tương ứng. \n",
    "                              // Kiểm tra zero padding.\n",
    "                              // Tính toán vị trí trọng số.\n",
    "                              // Thực hiện phép tích chập.\n",
    "                              // Với val là giá trị trong mảng input (có thể là 0.0f do thuộc phần padding), kernel: mảng trọng số, \n",
    "                              weight_idx: vị trí giá trị trọng số trong mảng kernel.\n",
    "                              sum += val * kernel[weight_idx];\n",
    "                          }\n",
    "                      }\n",
    "                  } \n",
    "                  sum += biases[c_out];  // Thêm bias\n",
    "                  // Gán sum cho giá trị pixel đầu ra.\n",
    "                  output[output_idx] = sum;\n",
    "              }\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "  ```\n",
    "  2) Cấu trúc vòng lặp chính:\n",
    "  ```c\n",
    "  // Cấu trúc vòng lặp huấn luyện chính\n",
    "  for (int epoch = 0; epoch < num_epochs; epoch++) {\n",
    "      float total_loss = 0.0f;\n",
    "      clock_t start_time = clock(); // Bắt đầu đo giờ\n",
    "\n",
    "      // 1. Xáo trộn dữ liệu (Data shuffling)\n",
    "      shuffle_indices(train_indices, num_train_images);\n",
    "\n",
    "      for (int batch_id = 0; batch_id < num_batches; batch_id++) {\n",
    "          // 2. Chuẩn bị dữ liệu batch\n",
    "          load_batch(autoencoder.input, train_images, train_indices, batch_id, batch_size);\n",
    "\n",
    "          // 3. Lan truyền xuôi (Forward pass)\n",
    "          // Dữ liệu đi qua: Conv -> ReLU -> MaxPool -> ... -> Decoder\n",
    "          forward_autoencoder(&autoencoder);\n",
    "\n",
    "          // 4. Tính toán Loss (MSE)\n",
    "          float batch_loss = MSE(autoencoder.input, autoencoder.output, input_size);\n",
    "          total_loss += batch_loss;\n",
    "\n",
    "          // 5. Lan truyền ngược (Backward pass)\n",
    "          // Tính gradient từ output ngược về input\n",
    "          backward_autoencoder(&autoencoder);\n",
    "\n",
    "          // 6. Cập nhật tham số (Update weights)\n",
    "          // W = W - learning_rate * gradient\n",
    "          update_autoencoder_parameters(&autoencoder, learning_rate);\n",
    "      }\n",
    "\n",
    "      // Kết thúc epoch: Tính thời gian thực thi epoch.\n",
    "      clock_t end_time = clock();\n",
    "      double epoch_time = ((double)(end_time - start_time)) / CLOCKS_PER_SEC;\n",
    "  }\n",
    "  ```\n",
    "#### Kết quả:\n",
    "- Thời gian huấn luyện cho mỗi epoch và tổng thời gian huấn luyện:\n",
    "  - Với mỗi epoch, phiên CPU sẽ thực thi trong khoảng 489 giây.\n",
    "  - Tổng thời gian thực thi 20 epoch là khoảng 9780 giây (tương đương gần với 2 giờ 43 phút).\n",
    "- Final reconstruction loss: 0.054788.\n",
    "- Sample reconstructed images (show original vs reconstructed)\n",
    "![Ảnh mẫu reconstructed bởi CPU](https://drive.google.com/uc?export=view&id=1HPJctlPGdm7VdnxSwX7QfXSTkSVR500y)\n",
    "- Memory usage\n",
    "#### Những điểm chính:\n",
    "1) Bài học rút ra từ thuật toán:\n",
    "- Qua quá trình tự cài đặt thủ công các lớp mạng nơ-ron và thuật toán lan truyền ngược (Backpropagation) trên CPU, chúng em đã rút ra những bài học quan trọng về bản chất của thuật toán:\n",
    "  - Cường độ tính toán cực lớn: Khi trực tiếp cài đặt thuật toán Convolution, chúng em nhận thấy rằng đây không chỉ là phép nhân ma trận đơn thuần mà là một chuỗi các phép tính tích vô hướng (dot product) trượt qua không gian đầu vào. Với mỗi lớp Conv2D, việc áp dụng các bộ lọc (filters) kích thước 3×3 lên toàn bộ chiều sâu của ảnh đầu vào tạo ra một khối lượng tính toán khổng lồ.\n",
    "  - Cơ chế nén và tái tạo thông tin: Việc cài đặt tuần tự các lớp của Autoencoder giúp nhóm có thể hình dung rõ cách Autoencoder học các đặc trưng.\n",
    "  - Kiểm soát biên và bộ nhớ: Thao tác trực tiếp với Padding và Stride cho thấy tầm quan trọng của việc tính toán chỉ số (indexing) chính xác. Một sai sót nhỏ tại biên không chỉ làm lệch kích thước Tensor mà còn gây lỗi truy cập bộ nhớ nghiêm trọng.\n",
    "2) Những hiểu biết sâu sắc đã hướng dẫn việc triển khai GPU:\n",
    "- Khai thác tính độc lập dữ liệu cho mô hình SIMT: Thông qua việc cài đặt thủ công các lớp Convolution, MaxPool và UpSample, chúng em nhận thấy các phép toán tại mỗi vị trí đầu ra (h,w,c) hoàn toàn độc lập. Giá trị của một pixel trong Feature Map đích không phụ thuộc vào việc tính toán các pixel lân cận. \n",
    "  - Định hướng GPU: Đặc tính này hoàn toàn phù hợp với kiến trúc SIMT (Single Instruction, Multiple Threads) của CUDA. Thay vì sử dụng vòng lặp tuần tự, chúng em sẽ thiết kế kernel sao cho mỗi luồng (thread) hoặc một nhóm luồng sẽ chịu trách nhiệm tính toán song song cho một điểm ảnh cụ thể, tận dụng tối đa số lượng nhân CUDA khổng lồ.\n",
    "- Chiến lược giải quyết nút thắt cổ chai tính toán: Việc quan sát mã nguồn CPU cho thấy lớp Conv2D sở hữu độ phức tạp tính toán lớn nhất với 6 vòng lặp lồng nhau. Đây chính là điểm nghẽn hiệu năng chính, chiếm phần lớn thời gian huấn luyện.\n",
    "  - Định hướng GPU: Để giải quyết vấn đề này, chiến lược song song hóa cần tập trung vào việc trải phẳng (flatten) các chiều của vòng lặp và ánh xạ chúng vào không gian lưới (Grid/Block) của GPU.\n",
    "- Tối ưu hóa mô hình truy cập bộ nhớ: Phân tích cơ chế \"cửa sổ trượt\" (sliding window) của phép tích chập cho thấy một lượng lớn dữ liệu đầu vào bị đọc lặp lại dư thừa. Cụ thể, với kernel 3×3, một pixel đầu vào được truy xuất để tính toán cho 9 pixel đầu ra khác nhau. Trên CPU, việc truy cập bộ nhớ liên tục nhưng tại các địa chỉ rời rạc gây lãng phí băng thông nghiêm trọng.\n",
    "  - Định hướng GPU: Việc chỉ dựa vào Global Memory trên GPU sẽ tạo ra độ trễ lớn. Nhận định này dẫn dắt nhóm đến việc ứng dụng Shared Memory Tiling. Bằng cách tải các khối dữ liệu (tiles) vào bộ nhớ chia sẻ tốc độ cao, các luồng trong cùng một block có thể tái sử dụng dữ liệu hiệu quả, giảm thiểu tối đa lưu lượng truy cập xuống Global Memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDIWzpuE0GLd"
   },
   "source": [
    "### 2.2. GPU cơ bản\n",
    "#### Mục tiêu:\n",
    "- Chuyển việc triển khai trên CPU sang trên GPU bằng song song hóa cơ bản cho các phép toán chính là Con2D, MaxPool2D, ReLU và UpSample2D.\n",
    "- So sánh output GPU với CPU để đảm bảo kết quả đúng so với CPU.\n",
    "- Thiết lập baseline hiệu suất GPU: đo thời gian thực thi theo kernel và tổng thời gian để làm mốc cho các version tối ưu phía sau.\n",
    "#### Chi tiết cài đặt:\n",
    "- Chiến lược song song hóa:\n",
    "  - Layout dữ liệu: Tensor được lưu dạng 1D liên tục theo NCHW với công thức tỉ số là\n",
    "  $$idx(n,c,h,w) = ((n \\cdot C + c)\\cdot H +h)\\cdot W +w$$\n",
    "  - Các kernel được thiết kế theo nguyên tắc:\n",
    "    - Các phép toán tạo output 4D như Conv/Pool/Upsample: 1 thread xử lý 1 phần tử output.\n",
    "    - Các phép toán \"element-wise\" như ReLU: 1 thread xử lý 1 phần tử.\n",
    "  - Cách ánh xạ thread:\n",
    "    - blockIdx.x và blockIdx.y quét theo không gian w và h.\n",
    "    - blockIdx.z gộp (N,C) hoặc (N, C_out) bằng chỉ số nc.\n",
    "- Kernel Design:\n",
    "  - Convolution kernel: thread-to-output mapping\n",
    "    - Ý tưởng: Mỗi thread tính đúng 1 phần tử output Y[n, c_out, h_out, w_out]\n",
    "    -\n",
    "  - Pooling kernel: Mỗi thread tính Y[n, c_out, h_out, w_out] bằng max của 4 phần tử trong cửa sổ 2x2.\n",
    "  - Upsample kernel: Mỗi thread ghi 1 pixel output, lấy từ output bằng phép chia nguyên.\n",
    "  - ReLU kernel (element-wise): Mỗi thread xử lý một phần tử.\n",
    "- Chiến lược quản lý bộ nhớ device: Sử dụng chiến lược cấp phát trước (pre-allocation/static). Toàn bộ bộ đệm trên device cho tham số mô hình (weights/biases), các tensor trung gian (activations) và gradient tương ứng được cudaMalloc một lần duy nhất trong hàm gpu_autoencoder_init() trước khi bắt đầu huấn luyện. Trong quá trình train, mỗi iteration chỉ cần copy input batch từ host sang device và tái sử dụng các buffer đã cấp phát cho các bước forward/backward, nhờ đó tránh việc cấp phát/giải phóng lặp lại trong vòng lặp huấn luyện.\n",
    "- Key Code Snippets:\n",
    "  - Hàm idx4():\n",
    "  ```\n",
    "  __device__ __host__ inline int idx4(int n, int c, int h, int w, int C, int H, int W)\n",
    "  {\n",
    "    return ((n * C + c) * H + h) * W + w;\n",
    "  }\n",
    "  ```\n",
    "  - Hàm Conv2D_forward:\n",
    "  - Ham \n",
    "#### Results:\n",
    "- Training time per epoch and total training time\n",
    "- Speedup over CPU baseline (include table and chart)\n",
    "- GPU memory usage\n",
    "- Sample reconstructed images\n",
    "![Ảnh mẫu reconstructed bởi GPU naive](https://drive.google.com/uc?export=view&id=1Phzzp3KKKRkMTYVaK5ykaM0lLNFVn5-o)\n",
    "- Verification that outputs match CPU (show error metrics)\n",
    "#### Profiling Analysis:\n",
    "- Basic profiling results (time spent in each kernel type)\n",
    "- Memory bandwidth utilization (if measured)\n",
    "- Initial bottleneck identification\n",
    "#### Key Takeaways:\n",
    "- What was surprisingly fast or slow?\n",
    "- Where do you see optimization opportunities?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmlPUJnS03BH"
   },
   "source": [
    "### 2.3. GPU Optimized Implementation - Version 1\n",
    "#### Optimization Focus:\n",
    "#### Objectives:\n",
    "- What specific optimization(s) you targeted\n",
    "- Expected performance improvement\n",
    "#### Implementation Details:\n",
    "- Optimization Techniques Applied\n",
    "  - Detailed explanation of the optimization (e.g., shared memory tiling)- Why this optimization should help\n",
    "  - Implementation approach\n",
    "- Key Code Snippets: Show the optimized kernel or key changes\n",
    "#### Results:\n",
    "- Training time comparison with previous version\n",
    "- Speedup over previous phase (incremental and cumulative)\n",
    "- Performance metrics (bandwidth utilization, occupancy)\n",
    "- Sample reconstructed images\n",
    "![Ảnh mẫu reconstructed bởi GPU version 1](https://drive.google.com/uc?export=view&id=1HxMYgUUDyIy5BUthej5hNJIPSvblqDiS)\n",
    "- Profiling comparison: before vs after\n",
    "#### Analysis:\n",
    "- Why did this optimization work (or not work as expected)?\n",
    "- What did profiling reveal?\n",
    "- What's the next bottleneck?\n",
    "#### Key Takeaways:\n",
    "- Lessons learned from this optimization\n",
    "- Applicability to other problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guwkMoVg1o1l"
   },
   "source": [
    "### 2.4. GPU Optimized Implementation - Version 2\n",
    "#### Optimization Focus:\n",
    "#### Objectives:\n",
    "- What specific optimization(s) you targeted\n",
    "- Expected performance improvement\n",
    "#### Implementation Details:\n",
    "- Optimization Techniques Applied\n",
    "  - Detailed explanation of the optimization (e.g., shared memory tiling)- Why this optimization should help\n",
    "  - Implementation approach\n",
    "- Key Code Snippets: Show the optimized kernel or key changes\n",
    "#### Results:\n",
    "- Training time comparison with previous version\n",
    "- Speedup over previous phase (incremental and cumulative)\n",
    "- Performance metrics (bandwidth utilization, occupancy)\n",
    "- Sample reconstructed images\n",
    "![Ảnh mẫu reconstructed bởi GPU version 2](https://drive.google.com/uc?export=view&id=1CgsqohZwarREM4Fmc1W5ynOcQRsZEYL1)\n",
    "- Profiling comparison: before vs after\n",
    "#### Analysis:\n",
    "- Why did this optimization work (or not work as expected)?\n",
    "- What did profiling reveal?\n",
    "- What's the next bottleneck?\n",
    "#### Key Takeaways:\n",
    "- Lessons learned from this optimization\n",
    "- Applicability to other problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dTqqiJd1sdH"
   },
   "source": [
    "### 2.5. Tích hợp SVM:\n",
    "#### Chi tiết triển khai:\n",
    "- Trích xuất đặc trưng từ Encoder:\n",
    "    - Quá trình trích xuất đặc trưng gồm 2 bước:\n",
    "        - Bước 1: Chúng em tải lại trọng số của mô hình đã huấn luyện. Thực hiện lại phần kiến trúc Encoder (từ lớp Input đến lớp Latent Space) và loại bỏ hoàn toàn phần Decoder. Điều này đảm bảo mạng nơ-ron hoạt động như một bộ trích xuất đặc trưng thuần túy.\n",
    "        - Bước 2: Mỗi ảnh đầu vào x (kích thước 32×32×3) được đưa qua các lớp tích chập (Conv2D) và giảm mẫu (MaxPooling). Tại lớp cuối cùng của Encoder, dữ liệu được cô đọng lại thành một tensor 3 chiều có kích thước 8×8×128.\n",
    "- Tích hợp LIBSVM: \n",
    "    - Thay vì nhúng trực tiếp thư viện LIBSVM vào mã nguồn C có thể gây phức tạp trong việc biên dịch và quản lý bộ nhớ, nhóm thực hiện chiến lược tương tác gián tiếp thông qua tệp tin. Quy trình được chia thành hai bước:\n",
    "        - Bước 1: Sử dụng Encoder đã huấn luyện để trích xuất đặc trưng và ghi ra tệp văn bản theo định dạng chuẩn của LIBSVM.\n",
    "        - Bước 2: Sử dụng thư viện LIBSVM (thông qua CLI) để đọc tệp dữ liệu này và thực hiện huấn luyện.\n",
    "- Lựa chọn siêu tham số: \n",
    "    - Loại SVM: C-SVC (C-Support Vector Classification).\n",
    "    - Loại kernel: Linear kernel (Nhân tuyến tính).\n",
    "    - Tham số phạt: C = 1.0.\n",
    "- Các đoạn mã chính:\n",
    "    1) Trích xuất đặc trưng dùng để huấn luyện:\n",
    "    ```c\n",
    "    // Lặp qua từng batch\n",
    "    for (int b = 0; b < num_batches_train; ++b) {\n",
    "        // Copy ảnh vào bộ đệm\n",
    "        // Thực hiện encoder\n",
    "        cpu_extract_features(&autoencoder, h_batch, cur_bs, h_latent);\n",
    "        // Ghi file theo format LIBSVM\n",
    "        for (int i = 0; i < cur_bs; ++i) {\n",
    "            int idx = start + i;\n",
    "            int label = data.train_labels[idx];\n",
    "            const float* feat = h_latent + i * AE_LATENT_DIM;\n",
    "            write_svm_line(f_train, label, feat, AE_LATENT_DIM);\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "    2) Mã huấn luyện SVM:\n",
    "    ```python\n",
    "    !./svm-train -s 0 -t 0 -c 1.0 \\\n",
    "    \"../opt2/train_svm.txt\" \\\n",
    "    ../opt2/model_ae_svm\n",
    "    ```\n",
    "#### Kết quả:\n",
    "- Thời gian trích xuất đặc trưng (50K train + 10K test):\n",
    "    - Phiên bản CPU: Khoảng 3 tiếng (cho 10K ảnh train và 2K ảnh test).\n",
    "    - Phiên bản GPU naive: Khoảng 4 phút 30 giây.\n",
    "    - Phiên bản tối ưu hoá GPU (Phiên bản 1): Khoảng 4 phút.\n",
    "    - Phiên bản tối ưu hoá GPU (Phiên bản 2): Khoảng 3 phút 40 giây.\n",
    "- Thời gian huấn luyện SVM:\n",
    "    - Phiên bản CPU huấn luyện khoảng 1 tiếng.\n",
    "    - Mỗi phiên bản GPU huấn luyện khoảng 7 tiếng.\n",
    "- Độ chính xác phân loại trên tập dữ liệu thử nghiệm: \n",
    "    - Phiên bản CPU: 56.65%, do nhóm em chỉ huấn luyện SVM với 10 ngàn ảnh nên sẽ không đạt được chính xác mong đợi là 60-65%.\n",
    "    - Phiên bản GPU naive: 63.63%.\n",
    "    - Phiên bản tối ưu hoá GPU (Phiên bản 1): 63.96%.\n",
    "    - Phiên bản tối ưu hoá GPU (Phiên bản 2): 64.25%.\n",
    "- Phân tích độ chính xác theo từng lớp:\n",
    "\n",
    "    1) Phiên bản CPU:\n",
    "\n",
    "    |Lớp|Độ chính xác (%)|\n",
    "    |---|----------------|\n",
    "    |0|11.8|\n",
    "    |1|13.4|\n",
    "    |2|7.9|\n",
    "    |3|8.7|\n",
    "    |4|8.6|\n",
    "    |5|6.8|\n",
    "    |6|15.6|\n",
    "    |7|13|\n",
    "    |8|15.6|\n",
    "    |9|11.9|\n",
    "\n",
    "    2) Phiên bản GPU naive:\n",
    "\n",
    "    |Lớp|Độ chính xác (%)|\n",
    "    |---|----------------|\n",
    "    |0|69.4|\n",
    "    |1|71.2|\n",
    "    |2|48.5|\n",
    "    |3|45.3|\n",
    "    |4|60.2|\n",
    "    |5|54.3|\n",
    "    |6|75.8|\n",
    "    |7|66.8|\n",
    "    |8|75|\n",
    "    |9|69.8|\n",
    "\n",
    "    3) Phiên bản tối ưu hoá GPU (Phiên bản 1):\n",
    "\n",
    "    |Lớp|Độ chính xác (%)|\n",
    "    |---|----------------|\n",
    "    |0|67.3|\n",
    "    |1|71.7|\n",
    "    |2|51|\n",
    "    |3|45.2|\n",
    "    |4|60.2|\n",
    "    |5|55|\n",
    "    |6|74.1|\n",
    "    |7|69|\n",
    "    |8|76|\n",
    "    |9|70.1|\n",
    "\n",
    "    4) Phiên bản tối ưu hoá GPU (Phiên bản 2):\n",
    "\n",
    "    |Lớp|Độ chính xác (%)|\n",
    "    |---|----------------|\n",
    "    |0|68.2|\n",
    "    |1|72.5|\n",
    "    |2|49.7|\n",
    "    |3|47|\n",
    "    |4|60.8|\n",
    "    |5|54.3|\n",
    "    |6|76|\n",
    "    |7|68.3|\n",
    "    |8|74.6|\n",
    "    |9|71.1|\n",
    "\n",
    "- Confusion matrix:\n",
    "1) Phiên bản CPU:\n",
    "\n",
    "![Confusion matrix cho CPU](https://drive.google.com/uc?export=view&id=1JXa1PKPK55oXImVMVrgwEAgf2hObp0Gb)\n",
    "\n",
    "2) Phiên bản GPU naive:\n",
    "\n",
    "![Confusion matrix cho GPU Naive](https://drive.google.com/uc?export=view&id=12FQrKBFRRpnVDVCJ71m5XZtWDsiOYmRm)\n",
    "\n",
    "3) Phiên bản tối ưu hoá GPU (Phiên bản 1):\n",
    "\n",
    "![Confusion matrix cho GPU V1](https://drive.google.com/uc?export=view&id=1YgcJr-rr7cHVnLTmdx84bUOEsOpu13de)\n",
    "\n",
    "4) Phiên bản tối ưu hoá GPU (Phiên bản 2):\n",
    "\n",
    "![Confusion matrix cho GPU V2](https://drive.google.com/uc?export=view&id=1EhF_rA_7LW-WbjapH_84-jbJ9u3mRrPK)\n",
    "\n",
    "#### Phân tích:\n",
    "- Những lớp dễ phân loại và khó phân loại nhất:\n",
    "    - Kết quả trên tập kiểm tra cho thấy mô hình hoạt động rất hiệu quả trên nhóm đối tượng nhân tạo (máy bay, ô tô) và các lớp có đặc trưng thị giác nổi bật như lớp 6 (ếch) và lớp 8 (tàu thủy). Sự vượt trội này xuất phát từ tính đặc thù của dữ liệu. Ví dụ, ảnh tàu thủy thường gắn liền với nền xanh đồng nhất (nước hoặc bầu trời), ít nhiễu nền, giúp Autoencoder dễ dàng cô lập đối tượng. Tương tự, ếch có hình thái cơ thể tròn trịa và tư thế ngồi đặc trưng, khác biệt hoàn toàn so với cấu trúc bốn chân của các loài thú khác, giúp mô hình dễ dàng phân tách . \n",
    "    - Tuy nhiên, độ chính xác bị giảm sút đáng kể ở các lớp động vật, đặc biệt là lớp 2 (chim) và lớp 3 (mèo) với độ chính xác chỉ đạt ngưỡng 50%. Cho thấy hai lớp này sẽ khó phân loại nhất do cấu trúc sinh học phức tạp của chúng có thể gây nhầm lẫn sang thực thể khác.\n",
    "    \n",
    "    **Kết luận:** Điều đó cho thấy, mặc dù SVM phân loại tốt các đối tượng có hình học cố định, nhưng việc trích xuất đặc trưng cho các đối tượng sinh học phức tạp vẫn là một thách thức, gợi ý rằng mô hình cần huấn luyện lâu hơn hoặc cần kiến trúc Autoencoder sâu hơn để bắt được các chi tiết tinh tế này.\n",
    "### - Ma trận nhầm lẫn tiết lộ điều gì?\n",
    "- Độ chính xác so với kỳ vọng: Trong phần mô tả, nêu rõ là kỳ vọng độ chính xác 60-65%. Ở đây tất cả các phiên bản đều đạt được độ chính xác kỳ vọng là 63-64% (ngoại trừ CPU không đạt do huấn luyện dữ liệu ít hơn).\n",
    "#### Những điểm chính cần ghi nhớ:\n",
    "- Chất lượng của các đặc trưng mô hình đã học: Kết quả đạt được từ việc huấn luyện mô hình cho thấy rằng những đặc trưng mà Autoencoder đã học được rất tốt. Từ đó giúp mô hình có khả năng phân loại tốt, và đạt được hiệu quả mong đợi.\n",
    "- Effectiveness of two-stage approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsPue2eb2Fkf"
   },
   "source": [
    "## 3. Comprehensive Performance Analysis\n",
    "### 3.1. Performance Comparison Across All Phases:\n",
    "#### Table Format:\n",
    "| Phase        | Training Time | Speedup (vs CPU) | Incremental Speedup | Memory Usage | Key Optimization        |\n",
    "|-------------|---------------|------------------|----------------------|-------------|-------------------------|\n",
    "| CPU Baseline| 1800s         | 1.0×             | -                    | -           | -                       |\n",
    "| GPU Basic   | 180s          | 10.0×            | 10.0×                | 2.1 GB      | Parallelization         |\n",
    "| GPU Opt v1  | 45s           | 40.0×            | 4.0×                 | 2.3 GB      | Shared memory           |\n",
    "| GPU Opt v2  | 25s           | 72.0×            | 1.8×                 | 2.5 GB      | Kernel Fusion + Streams |\n",
    "\n",
    "#### Visualizations:\n",
    "- Bar chart showing training time across phases\n",
    "- Line graph showing cumulative speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EttBWMjc2aAa"
   },
   "source": [
    "## 4. Bài học và khó khăn trong quá trình thực hiện:\n",
    "### 4.1. Những kỹ thuật quan trọng:\n",
    "- Lập trình CUDA:\n",
    "  - Hiểu rõ cách tổ chức kernel theo mô hình grid/block/thread, đặc biệt là chiến lược ánh xạ (x,y) cho không gian (h,w) và z cho (batch, channel) để xử lý tensor NCHW hiệu quả.\n",
    "  - Nắm vững các vấn đề khi làm việc với CUDA như: quản lý truy cập bộ nhớ, tránh ghi đè (race condition) và quản lý lỗi bằng CHECK_CUDA.\n",
    "  - Hiểu được tầm quan trọng của việc đồng bộ các hoạt động được thực thi trên GPU để đảm bảo thu được kết quả đúng và hiệu quả.\n",
    "- Deep Learning: \n",
    "  - Hiểu được kiến trúc của mô hình Autoencoder, cách mà mô hình hoạt động để học và trích xuất được đặc trưng không cần nhãn.\n",
    "  - Biết được các hoạt động của các lớp trong mô hình (Conv, Pool, Upsample), cách hoạt động của encoder-decoder.\n",
    "- Tối ưu hiệu suất:\n",
    "  - Thiết lập được baseline để tối ưu: Trước khi thực hiện tối ưu cần phải chính xác và có mốc đo để so sánh.\n",
    "  - Thấy rõ được bottleneck của baseline, từ đó đưa ra các chiến lược tối ưu thích hợp để đạt được hiệu suất tốt nhất.  \n",
    "### 4.2. Khó khăn chính và giải pháp:\n",
    "#### - Khó khăn 1: Chuyển code từ CPU sang GPU vẫn giữ đúng logic và độ chính xác\n",
    "- Vấn đề: Khi chuyển đổi từng layer sang GPU, rất dễ sai ở phần chỉ số (index), mapping thread với output, chỉ cần lệch 1 chỉ số là output sai toàn bộ.\n",
    "- Giải pháp: \n",
    "  - Có test để verify kết quả so với CPU theo từng kernel.\n",
    "  - Dùng một layout index thống nhất là idx4().\n",
    "- Bài học: Cần phải đảm bảo chính xác từng baseline viết bằng CPU, có test để verify kết quả của GPU và CPU, sau đó mới tập trung vào tối ưu.\n",
    "#### - Khó khăn 2: Train trên số ít epoch khiến mô hình hội tụ không tốt.\n",
    "- Vấn đề: Do hạn chế về mặt tài nguyên, nhóm chỉ có thể train trên số lượng ít epoch. Có trường hợp đạt loss thấp nhưng khi extract_features và đưa sang bộ phân loại SVM thì accuracy chỉ đạt quanh 10%.\n",
    "- Giải pháp:\n",
    "  - Xem xét lại phần khởi tạo trọng số, điều chỉnh khoảng khởi tạo tốt hơn.\n",
    "  - Tăng learning rate\n",
    "- Bài học:\n",
    "  - Reconstruction loss thấp không đảm bảo latent representation sẽ tốt, vẫn có trường hợp tệ là đặc trưng được trích xuất không mang nhiều thông tin hỗ trợ phân loại lớp.\n",
    "  - Khởi tạo trọng số và learning rate trong vài trường hợp có ảnh hưởng mạnh đến hiệu suất mô hình. Khởi tạo không hù hợp có thể khiến mô hình hội tụ kém, tạo ra latent không có ý nghĩa phân loại. Tương tự, learning rate quá nhỏ khiến mô hình học chậm, quá lớn lại đi lệch đi điểm tối ưu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMYtXPS12o8t"
   },
   "source": [
    "## 5. Conclusion and Future Work:\n",
    "### 5.1. Project Summary:\n",
    "- Recap of what was accomplished\n",
    "- Final performance metrics summary table\n",
    "- Achievement of original objectives\n",
    "### 5.2. Key Achievements:\n",
    "Highlight your best results:\n",
    "- Maximum speedup achieved\n",
    "- Classification accuracy\n",
    "- Most successful optimization\n",
    "- Technical skills mastered\n",
    "### 5.3. Limitations:\n",
    "Honestly discuss:\n",
    "- Current performance bottlenecks\n",
    "- Accuracy limitations\n",
    "- Implementation constraints\n",
    "### 5.4. Future Improvements:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
